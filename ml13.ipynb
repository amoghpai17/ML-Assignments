{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e04c94",
   "metadata": {},
   "source": [
    "1.Provide an example of the concepts of Prior, Posterior, and Likelihood.\n",
    "\n",
    "ANS-\n",
    "Suppose you want to estimate the probability of a coin landing heads up when tossed. You have no prior knowledge about the coin, so you assume that the probability of heads is equally likely to the probability of tails, i.e., P(Heads) = 0.5 and P(Tails) = 0.5. This assumption about the probability of the coin landing heads up is known as the prior distribution.\n",
    "\n",
    "Now, you toss the coin 10 times and get 7 heads and 3 tails. The results of the coin tosses are your data. You want to update your knowledge of the coin's probability of landing heads up based on this data.\n",
    "\n",
    "The likelihood is the probability of observing the data given the probability of the coin landing heads up. In this case, the likelihood is the probability of getting 7 heads and 3 tails when the probability of the coin landing heads up is 0.5. This can be calculated using the binomial distribution formula and is approximately 0.117.\n",
    "\n",
    "The posterior distribution is the updated probability of the coin landing heads up given the data. It can be calculated using Bayes' theorem, which tells us that:\n",
    "\n",
    "P(Heads | Data) = P(Data | Heads) * P(Heads) / P(Data)\n",
    "\n",
    "where P(Heads | Data) is the posterior probability, P(Data | Heads) is the likelihood, P(Heads) is the prior probability, and P(Data) is the marginal probability of the data.\n",
    "\n",
    "Using Bayes' theorem, we can calculate the posterior probability of the coin landing heads up:\n",
    "\n",
    "P(Heads | Data) = 0.117 * 0.5 / P(Data)\n",
    "\n",
    "where P(Data) is the probability of observing 7 heads and 3 tails, which can be calculated using the binomial distribution formula and is approximately 0.117.\n",
    "\n",
    "Therefore, the posterior probability of the coin landing heads up is:\n",
    "\n",
    "P(Heads | Data) = 0.117 * 0.5 / 0.117 â‰ˆ 0.5\n",
    "\n",
    "This means that the probability of the coin landing heads up is still about 50%, which is the same as our prior assumption, even after observing 7 heads and 3 tails in 10 tosses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2f37b",
   "metadata": {},
   "source": [
    "2.What role does Baye's theorem play in the concept learning principle?\n",
    "\n",
    "ANS-\n",
    "Bayes' theorem provides a way to update our beliefs about the probability of a hypothesis or concept given new evidence or data. Specifically, Bayes' theorem tells us how to calculate the probability of a hypothesis given the data, given the prior probability of the hypothesis, and the probability of the data given the hypothesis.\n",
    "\n",
    "In the context of concept learning, Bayes' theorem is used to update our beliefs about the probability of a particular concept or category given new examples or instances of that concept. For example, suppose we are trying to learn a concept \"dog\" from a set of examples that includes pictures of various dogs. Initially, we might have a prior belief about what characteristics define a \"dog,\" but as we see more examples of dogs, our beliefs about the concept will change. Bayes' theorem provides a way to update our beliefs about the probability of an example being a \"dog\" given the data (i.e., the picture of the dog), the prior probability of the \"dog\" concept, and the probability of the data given the concept (i.e., how likely the picture is to be a \"dog\").\n",
    "\n",
    "By iteratively applying Bayes' theorem to update our beliefs about the concept, we can learn the concept more accurately over time, allowing us to make better predictions about new examples of that concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5784dc13",
   "metadata": {},
   "source": [
    "3.Offer an example of how the Nave Bayes classifier is used in real life.\n",
    "\n",
    "ANS-\n",
    "common application of Naive Bayes classifiers is spam filtering. Spam filters are software programs designed to identify and filter out unsolicited and unwanted email messages, also known as spam. Naive Bayes classifiers can be used to classify incoming emails as spam or not spam based on the content of the email.\n",
    "\n",
    "For example, suppose we have a dataset of labeled emails where each email is labeled as either spam or not spam. The content of each email can be represented as a bag of words, i.e., a set of words that occur in the email along with their frequency. We can then train a Naive Bayes classifier on this dataset to learn the probability distribution of words for spam and non-spam emails.\n",
    "\n",
    "When a new email arrives, the Naive Bayes classifier can predict whether it is spam or not spam by calculating the probability of the email being spam or not spam given the bag of words representation of the email. The Naive Bayes classifier assumes that the words in the email are independent of each other, which is a naive assumption, but often works well in practice.\n",
    "\n",
    "If the probability of the email being spam is above a certain threshold, the email is classified as spam and moved to the spam folder. Otherwise, it is classified as not spam and moved to the inbox. This way, the Naive Bayes classifier helps to filter out unwanted emails and improves the user's email experience.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b037dc93",
   "metadata": {},
   "source": [
    "4.Can the Nave Bayes classifier be used on continuous numeric data? If so, how can you go about\n",
    "doing it?\n",
    "\n",
    "ANS-\n",
    "Yes, the Naive Bayes classifier can be used on continuous numeric data, although it requires some modifications to the standard algorithm.\n",
    "\n",
    "To use the Naive Bayes classifier with continuous numeric data,we need to:\n",
    "\n",
    "1 -Assume a probability distribution for each feature given the class variable, such as the Gaussian distribution.\n",
    "2 -Estimate the mean and variance of each feature separately for each class variable from the training data.\n",
    "3 -Calculate the posterior probability of each class variable given the features of a new instance using Bayes' theorem.\n",
    "4 -Classify the new instance based on the class variable with the highest posterior probability.\n",
    "\n",
    "By making these modifications to the standard Naive Bayes algorithm, we can effectively use Naive Bayes to classify instances with continuous numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c774d",
   "metadata": {},
   "source": [
    "5.What are Bayesian Belief Networks, and how do they work? What are their applications? Are they\n",
    "capable of resolving a wide range of issues?\n",
    "\n",
    "ANS-\n",
    "Bayesian belief networks (BBNs) are probabilistic graphical models that represent a set of random variables and their conditional dependencies through a directed acyclic graph. In a BBN, each node in the graph represents a random variable, and the directed edges represent the conditional dependencies between the variables. The nodes and edges are assigned probability distributions, and the BBN can be used to calculate the joint probability distribution over all the variables.\n",
    "\n",
    "BBNs work by propagating probabilities through the graph, using Bayes' theorem and the chain rule of probability to compute the probability of any subset of variables given the values of the other variables. This allows us to reason about uncertainty and make predictions based on incomplete or uncertain data.\n",
    "\n",
    "\n",
    "Some common applications of BBNs include:\n",
    "1 -Diagnosis and decision-making: BBNs can be used to diagnose medical conditions or make decisions based on uncertain or incomplete information.\n",
    "\n",
    "2 -Risk analysis and management: BBNs can be used to assess and manage risks in complex systems, such as financial markets or industrial processes.\n",
    "\n",
    "3 -Forecasting and prediction: BBNs can be used to make predictions about future events based on historical data and other relevant factors.\n",
    "\n",
    "4 -Recommender systems: BBNs can be used to make personalized recommendations based on the preferences and behavior of users.\n",
    "\n",
    "\n",
    "BBNs are capable of resolving a wide range of issues, but their effectiveness depends on the quality of the data, the complexity of the model, and the expertise of the modeler. BBNs can handle large, complex models with many variables and dependencies, but they may require a significant amount of data and computational resources to learn and infer probabilities accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3343e02",
   "metadata": {},
   "source": [
    "6.Passengers are checked in an airport screening system to see if there is an intruder. Let I be the\n",
    "random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the\n",
    "variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98\n",
    "and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered,\n",
    "implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) =\n",
    "0.00001. What are the chances that an alarm would be triggered when an individual is actually an\n",
    "intruder?\n",
    "\n",
    "ANS-\n",
    "\n",
    "We can use Bayes' theorem to calculate the probability that an individual is an intruder given that an alarm has been triggered:\n",
    "\n",
    "P(I=1|A=1) = P(A=1|I=1) * P(I=1) / P(A=1)\n",
    "\n",
    "where P(A=1) is the total probability of the alarm being triggered, which can be calculated using the law of total probability:\n",
    "\n",
    "P(A=1) = P(A=1|I=1) * P(I=1) + P(A=1|I=0) * P(I=0)\n",
    "\n",
    "Substituting the given probabilities, we get:\n",
    "\n",
    "P(A=1) = 0.98 * 0.00001 + 0.001 * (1 - 0.00001) = 0.0010098\n",
    "\n",
    "Now we can calculate the probability that an individual is an intruder given that an alarm has been triggered:\n",
    "\n",
    "P(I=1|A=1) = 0.98 * 0.00001 / 0.0010098 = 0.009709\n",
    "\n",
    "Therefore, the chances that an alarm would be triggered when an individual is actually an intruder are approximately 0.97% (0.009709 or 0.9709%). This means that the screening system has a relatively high false positive rate (triggering an alarm when there is no intruder), which can cause inconvenience and delays for passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1851cbd",
   "metadata": {},
   "source": [
    "7.An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are\n",
    "not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of\n",
    "those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those\n",
    "actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were\n",
    "antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune\n",
    "(random variable D).\n",
    "\n",
    "ANS-\n",
    "To calculate the likelihood that a person who tests positive is actually immune (resistant to the antibiotic), we need to use Bayes' theorem, which states that:\n",
    "\n",
    "P(D | T) = P(T | D) * P(D) / P(T)\n",
    "\n",
    "where P(D | T) is the probability of being immune given a positive test result, P(T | D) is the probability of a positive test result given that the person is immune, P(D) is the prior probability of being immune (i.e., the prevalence of antibiotic resistance in the population), and P(T) is the probability of a positive test result.\n",
    "\n",
    "We are given that:\n",
    "\n",
    "P(T | not D) = 0.01 (false positive rate)\n",
    "P(not T | D) = 0.05 (false negative rate)\n",
    "P(D) = 0.02 (prevalence of antibiotic resistance)\n",
    "To calculate P(T), we need to use the law of total probability:\n",
    "\n",
    "P(T) = P(T | D) * P(D) + P(T | not D) * P(not D)\n",
    "= (1 - P(not T | D)) * P(D) + P(T | not D) * (1 - P(D))\n",
    "= 0.95 * 0.02 + 0.01 * 0.98\n",
    "= 0.0121\n",
    "\n",
    "Now we can calculate P(D | T):\n",
    "\n",
    "P(D | T) = P(T | D) * P(D) / P(T)\n",
    "= (1 - P(not T | D)) * P(D) / P(T)\n",
    "= (1 - 0.05) * 0.02 / 0.0121\n",
    "= 0.326\n",
    "\n",
    "Therefore, the likelihood that a person who tests positive is actually immune (resistant to the antibiotic) is 0.326 or 32.6%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a63a9",
   "metadata": {},
   "source": [
    "8.In order to prepare for the test, a student knows that there will be one question in the exam that\n",
    "is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and\n",
    "50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10\n",
    "type B problems, and 6 of 10 type C problems.\n",
    "\n",
    "1.What is the likelihood that the student can solve the exam problem?\n",
    "\n",
    "To calculate the likelihood that the student can solve the exam problem, we need to use the law of total probability:\n",
    "P(solve) = P(solve|A) * P(A) + P(solve|B) * P(B) + P(solve|C) * P(C)\n",
    "\n",
    "where P(solve|A) is the probability that the student can solve a problem of type A, and similarly for B and C.\n",
    "\n",
    "From the given information, we have:\n",
    "\n",
    "P(solve|A) = 9/10\n",
    "P(solve|B) = 2/10\n",
    "P(solve|C) = 6/10\n",
    "P(A) = 0.3\n",
    "P(B) = 0.2\n",
    "P(C) = 0.5\n",
    "\n",
    "Substituting these values, we get:\n",
    "\n",
    "P(solve) = (9/10 * 0.3) + (2/10 * 0.2) + (6/10 * 0.5) = 0.63\n",
    "\n",
    "Therefore, the likelihood that the student can solve the exam problem is 0.63 or 63%.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2.Given the student's solution, what is the likelihood that the problem was of form A?\n",
    "\n",
    "\n",
    "To calculate the likelihood that the problem was of form A given the student's solution, we can use Bayes' theorem:\n",
    "P(A|solve) = P(solve|A) * P(A) / P(solve)\n",
    "\n",
    "where P(solve) is the probability of solving the problem, which we calculated in part 1.\n",
    "\n",
    "Substituting the values, we get:\n",
    "\n",
    "P(A|solve) = (9/10 * 0.3) / 0.63 = 0.4286\n",
    "\n",
    "Therefore, the likelihood that the problem was of form A given the student's solution is approximately 0.43 or 43%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87248534",
   "metadata": {},
   "source": [
    "9.A bank installs a CCTV system to track and photograph incoming customers. Despite the constant\n",
    "influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into\n",
    "the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for\n",
    "simplicity, we assume that either there is 1 customer or none, not the case of multiple customers). If\n",
    "\n",
    "there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the\n",
    "camera can take a false photograph with a 10% chance of detecting movement from other objects.\n",
    "\n",
    "1.How many customers come into the bank on a daily basis (10 hours)?\n",
    "\n",
    "The bank is open for 10 hours, which is 600 minutes. Dividing this into 5-minute bins, we have 600/5 = 120 time periods. The probability of a customer coming in each time period is 0.05. The number of customers coming in during a day can be modeled as a binomial distribution with parameters n=120 (number of time periods) and p=0.05 (probability of a customer coming in a time period). The expected number of customers coming in is therefore:\n",
    "E(X) = n * p = 120 * 0.05 = 6\n",
    "\n",
    "Therefore, we can expect an average of 6 customers coming into the bank on a daily basis.\n",
    "\n",
    "\n",
    "\n",
    "2.On a daily basis, how many fake photographs (photographs taken when there is no\n",
    "customer) and how many missed photographs (photographs taken when there is a customer) are\n",
    "there?\n",
    "\n",
    "For each 5-minute time period, there are two possible outcomes: a customer comes in, or a customer doesn't come in. If a customer comes in, the CCTV will detect them with a probability of 0.99, and if a customer doesn't come in, the CCTV may take a false photograph with a probability of 0.1. Therefore, we can model the number of fake photographs and missed photographs as two binomial distributions, with parameters n=120 (number of time periods) and p1=0.01 (probability of a missed photograph) and p2=0.1 (probability of a false photograph), respectively. The expected number of missed photographs and false photographs are:\n",
    "E(missed) = n * p1 = 120 * 0.01 = 1.2\n",
    "E(false) = n * p2 = 120 * 0.1 = 12\n",
    "\n",
    "Therefore, we can expect an average of 1.2 missed photographs and 12 false photographs on a daily basis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3.Explain likelihood that there is a customer if there is a photograph?\n",
    "\n",
    "To calculate the likelihood that there is a customer if there is a photograph, we can use Bayes' theorem:\n",
    "P(customer|photograph) = P(photograph|customer) * P(customer) / P(photograph)\n",
    "\n",
    "where P(photograph|customer) is the probability of taking a photograph given that there is a customer, P(customer) is the probability of a customer coming in during a 5-minute time period, and P(photograph) is the probability of taking a photograph, which is the sum of the probabilities of taking a photograph given that there is a customer and the probability of taking a photograph given that there is no customer:\n",
    "\n",
    "P(photograph) = P(photograph|customer) * P(customer) + P(photograph|no customer) * P(no customer)\n",
    "= 0.99 * 0.05 + 0.1 * 0.95\n",
    "= 0.1045\n",
    "\n",
    "Substituting the values, we get:\n",
    "\n",
    "P(customer|photograph) = 0.99 * 0.05 / 0.1045\n",
    "= 0.474\n",
    "\n",
    "Therefore, the likelihood that there is a customer if there is a photograph is approximately 0.474 or 47.4%.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
